import{_ as a,c as t,o as i,ag as o}from"./chunks/framework.S-Qvb3wi.js";const m=JSON.parse('{"title":"OCR Service","description":"","frontmatter":{},"headers":[],"relativePath":"services/ocr-service.md","filePath":"services/ocr-service.md"}'),s={name:"services/ocr-service.md"};function r(c,e,n,l,h,d){return i(),t("div",null,e[0]||(e[0]=[o(`<h1 id="ocr-service" tabindex="-1">OCR Service <a class="header-anchor" href="#ocr-service" aria-label="Permalink to &quot;OCR Service&quot;">​</a></h1><p>The OCR (Optical Character Recognition) and text extraction service is responsible for extracting plain text content from various file formats, such as PDFs, Office documents, and more. This is a crucial component for making email attachments searchable.</p><h2 id="overview" tabindex="-1">Overview <a class="header-anchor" href="#overview" aria-label="Permalink to &quot;Overview&quot;">​</a></h2><p>The system employs a two-pronged approach for text extraction:</p><ol><li><strong>Primary Extractor (Apache Tika)</strong>: A powerful and versatile toolkit that can extract text from a wide variety of file formats. It is the recommended method for its superior performance and format support.</li><li><strong>Legacy Extractor</strong>: A fallback mechanism that uses a combination of libraries (<code>pdf2json</code>, <code>mammoth</code>, <code>xlsx</code>) for common file types like PDF, DOCX, and XLSX. This is used when Apache Tika is not configured.</li></ol><p>The main logic resides in <code>packages/backend/src/helpers/textExtractor.ts</code>, which decides which extraction method to use based on the application&#39;s configuration.</p><h2 id="configuration" tabindex="-1">Configuration <a class="header-anchor" href="#configuration" aria-label="Permalink to &quot;Configuration&quot;">​</a></h2><p>To enable the primary text extraction method, you must configure the URL of an Apache Tika server instance in your environment variables.</p><p>In your <code>.env</code> file, set the <code>TIKA_URL</code>:</p><div class="language-env vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">env</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># .env.example</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Apache Tika Integration</span></span>
<span class="line"><span># ONLY active if TIKA_URL is set</span></span>
<span class="line"><span>TIKA_URL=http://tika:9998</span></span></code></pre></div><p>If <code>TIKA_URL</code> is not set, the system will automatically fall back to the legacy extraction methods. The service performs a health check on startup to verify connectivity with the Tika server.</p><h2 id="file-size-limits" tabindex="-1">File Size Limits <a class="header-anchor" href="#file-size-limits" aria-label="Permalink to &quot;File Size Limits&quot;">​</a></h2><p>To prevent excessive memory usage and processing time, the service imposes a general size limit on files submitted for text extraction. Files larger than the configured limit will be skipped.</p><ul><li><strong>With Apache Tika</strong>: The maximum file size is <strong>100MB</strong>.</li><li><strong>With Legacy Fallback</strong>: The maximum file size is <strong>50MB</strong>.</li></ul><h2 id="supported-file-formats" tabindex="-1">Supported File Formats <a class="header-anchor" href="#supported-file-formats" aria-label="Permalink to &quot;Supported File Formats&quot;">​</a></h2><p>The service&#39;s ability to extract text depends on whether it&#39;s using Apache Tika or the legacy fallback methods.</p><h3 id="with-apache-tika" tabindex="-1">With Apache Tika <a class="header-anchor" href="#with-apache-tika" aria-label="Permalink to &quot;With Apache Tika&quot;">​</a></h3><p>When <code>TIKA_URL</code> is configured, the service can process a vast range of file formats. Apache Tika is designed for broad compatibility and supports hundreds of file types, including but not limited to:</p><ul><li>Portable Document Format (PDF)</li><li>Microsoft Office formats (DOC, DOCX, PPT, PPTX, XLS, XLSX)</li><li>OpenDocument Formats (ODT, ODS, ODP)</li><li>Rich Text Format (RTF)</li><li>Plain Text (TXT, CSV, JSON, XML, HTML)</li><li>Image formats with OCR capabilities (PNG, JPEG, TIFF)</li><li>Archive formats (ZIP, TAR, GZ)</li><li>Email formats (EML, MSG)</li></ul><p>For a complete and up-to-date list, please refer to the official <a href="https://tika.apache.org/3.2.3/formats.html" target="_blank" rel="noreferrer">Apache Tika documentation</a>.</p><h3 id="with-legacy-fallback" tabindex="-1">With Legacy Fallback <a class="header-anchor" href="#with-legacy-fallback" aria-label="Permalink to &quot;With Legacy Fallback&quot;">​</a></h3><p>When Tika is not configured, text extraction is limited to the following formats:</p><ul><li><code>application/pdf</code> (PDF)</li><li><code>application/vnd.openxmlformats-officedocument.wordprocessingml.document</code> (DOCX)</li><li><code>application/vnd.openxmlformats-officedocument.spreadsheetml.sheet</code> (XLSX)</li><li>Plain text formats such as <code>text/*</code>, <code>application/json</code>, and <code>application/xml</code>.</li></ul><h2 id="features-of-the-tika-integration-ocrservice" tabindex="-1">Features of the Tika Integration (<code>OcrService</code>) <a class="header-anchor" href="#features-of-the-tika-integration-ocrservice" aria-label="Permalink to &quot;Features of the Tika Integration (\`OcrService\`)&quot;">​</a></h2><p>The <code>OcrService</code> (<code>packages/backend/src/services/OcrService.ts</code>) provides several enhancements to make text extraction efficient and robust.</p><h3 id="caching" tabindex="-1">Caching <a class="header-anchor" href="#caching" aria-label="Permalink to &quot;Caching&quot;">​</a></h3><p>To avoid redundant processing of the same file, the service implements a simple LRU (Least Recently Used) cache.</p><ul><li><strong>Cache Key</strong>: A SHA-256 hash of the file&#39;s buffer is used as the cache key.</li><li><strong>Functionality</strong>: If a file with the same hash is processed again, the text content is served directly from the cache, saving significant processing time.</li><li><strong>Statistics</strong>: The service keeps track of cache hits, misses, and the hit rate for performance monitoring.</li></ul><h3 id="concurrency-management-semaphore" tabindex="-1">Concurrency Management (Semaphore) <a class="header-anchor" href="#concurrency-management-semaphore" aria-label="Permalink to &quot;Concurrency Management (Semaphore)&quot;">​</a></h3><p>Extracting text from large files can be resource-intensive. To prevent the Tika server from being overwhelmed by multiple requests for the <em>same file</em> simultaneously (e.g., during a large import), a semaphore mechanism is used.</p><ul><li><strong>Functionality</strong>: If a request for a specific file (identified by its hash) is already in progress, any subsequent requests for the same file will wait for the first one to complete and then use its result.</li><li><strong>Benefit</strong>: This deduplicates parallel processing efforts and reduces unnecessary load on the Tika server.</li></ul><h3 id="health-check-and-dns-fallback" tabindex="-1">Health Check and DNS Fallback <a class="header-anchor" href="#health-check-and-dns-fallback" aria-label="Permalink to &quot;Health Check and DNS Fallback&quot;">​</a></h3><ul><li><strong>Availability Check</strong>: The service includes a <code>checkTikaAvailability</code> method to verify that the Tika server is reachable and operational. This check is performed on application startup.</li><li><strong>DNS Fallback</strong>: For convenience in Docker environments, if the Tika URL uses the hostname <code>tika</code> (e.g., <code>http://tika:9998</code>), the service will automatically attempt a fallback to <code>localhost</code> if the initial connection fails.</li></ul><h2 id="legacy-fallback-methods" tabindex="-1">Legacy Fallback Methods <a class="header-anchor" href="#legacy-fallback-methods" aria-label="Permalink to &quot;Legacy Fallback Methods&quot;">​</a></h2><p>When Tika is not available, the <code>extractTextLegacy</code> function in <code>textExtractor.ts</code> handles extraction for a limited set of MIME types:</p><ul><li><code>application/pdf</code>: Processed using <code>pdf2json</code>. Includes a 50MB size limit and a 5-second timeout to prevent memory issues.</li><li><code>application/vnd.openxmlformats-officedocument.wordprocessingml.document</code> (DOCX): Processed using <code>mammoth</code>.</li><li><code>application/vnd.openxmlformats-officedocument.spreadsheetml.sheet</code> (XLSX): Processed using <code>xlsx</code>.</li><li>Plain text formats (<code>text/*</code>, <code>application/json</code>, <code>application/xml</code>): Converted directly from the buffer.</li></ul>`,36)]))}const f=a(s,[["render",r]]);export{m as __pageData,f as default};
